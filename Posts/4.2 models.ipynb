{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/FUlyankin/ekenam_grand_research/master/images/cover.png\">\n",
    "</center>\n",
    "\n",
    "\n",
    "# <center> Иканам гранд рисёрч </center>\n",
    "## <center>  Часть четвёртая: моделирование. Строительство модели. </center>\n",
    "\n",
    "\n",
    "Проект **Иканам гранд рисёрч** реализуется [Иканам стьюдентс коммьюнити,](https://vk.com/ikanam)\n",
    "в частности [вот этим парнем по имени Филипп.](https://vk.com/ppilif) Если вы нашли ошибку или у вас есть предложения, замечания, деньги, слава или женщины, можно ему написать. Весь говнокод, использованный в исследовании распространяется по лицензии [Creative Commons CC BY-NC-SA 4.0.](https://creativecommons.org/licenses/by-nc-sa/4.0/) Его можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала. При наличии технической возможности необходимо также указать активную гиперссылку на [страницу рисёрча.](https://github.com/FUlyankin/ekenam_grand_research)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вместо введения\n",
    "\n",
    "В этой почиташке мы наконец то поговорим про моделирование отчислений. В ходе этого разговора мы обсудим: \n",
    "\n",
    "* Какие два великих вопроса стоят перед анализом данных и кого надо принести в жертву, чтобы все вопросы порешать;\n",
    "* Что такое задача классификации\n",
    "* Что за метрики качества такие \n",
    "* Предельные эффекты и коф т3йзщо/щоуЗуфзщуфп\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Два великих вопроса \n",
    "\n",
    "Анализ данных — это довольно обширная область знания. Она включает в себя классический матстат, эконометрику, машинное обучение и многие другие более специфические вещи. Анализ данных занимается тем, что ищет ответ на [два великих вопроса:](https://www.coursera.org/learn/ekonometrika/lecture/S7E9y/1-1-1-sut-mietoda-naimien-shikh-kvadratov) \n",
    "\n",
    "* Как устроен мир? Как переменная $y$ зависит от переменной $x$? \n",
    "* Что будет завтра? Как спрогнозировать переменную $y$? \n",
    "\n",
    "Обычно для поиска ответов на эти два вопроса используются модели. Эти модели оцениваются с помощью собранных данных. На работу каждой модели накладываются какие-то ограничения. Оценивая параметры в моделях, мы хотим, чтобы они обладали тремя свойствами: \n",
    "\n",
    "1. **Несмещенность** — чем больше у нас наблюдений, тем ближе среднее значение наших оценок к истиному значению параметра;\n",
    "2. **Состоятельность** — чем больше данных, тем ближе наши оценки к истине (почти наверное, если вы понимаете о чём я);\n",
    "3. **Эффективность** — разброс нашей оценки минимален в некотором классе оценок, если данные меняются, наша оценка меняется менее сильно, нежели другие.\n",
    "\n",
    "В зависимости от того на какой из двух вопросов мы ищем ответ, мы можем приносить некоторые свойства в жертву."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Классификация\n",
    "\n",
    "Чтобы понять какие люди не справляются с 1 курсом и построить прогнозы для новых первокурсников, нам придётся решать задачу классификации. Класс с меткой $1$ означает, что человек закончил первый курс, класс с меткой $0$, что не закончил. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Для моделирования мы будем исполь\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия предсказывает вероятности принадлежности объекта к каждому классу. Сумма ответов логистической регрессии на одном объекте для всех классов равна единице.\n",
    "\n",
    "$$ \\sum_{k=1}^K \\pi_{ik} = 1, \\quad \\pi_k \\equiv P\\,(y_i = k \\mid x_i, \\theta), $$\n",
    "\n",
    "где:\n",
    "- $\\pi_{ik}$ - вероятность принадлежности объекта $x_i$ из выборки $X$ к классу $k$\n",
    "- $\\theta$ - внутренние параметры алгоритма, которые настраиваются в процессе обучения, в случае логистической регрессии - $w, b$\n",
    "\n",
    "Из этого свойства модели в случае бинарной классификации требуется вычислить лишь вероятность принадлежности объекта к одному из классов (вторая вычисляется из условия нормировки вероятностей). Эта вероятность вычисляется, используя логистическую функцию:\n",
    "\n",
    "$$ P\\,(y_i = 1 \\mid x_i, \\theta) = \\frac{1}{1 + \\exp(-w^T x_i-b)} $$\n",
    "\n",
    "Параметры $w$ и $b$ находятся, как решения следующей задачи оптимизации (указаны функционалы с L1 и L2 регуляризацией, с которыми вы познакомились в предыдущих заданиях):\n",
    "\n",
    "L2-regularization:\n",
    "\n",
    "$$ Q(X, y, \\theta) = \\frac{1}{2} w^T w + C \\sum_{i=1}^l \\log ( 1 + \\exp(-y_i (w^T x_i + b ) ) ) \\longrightarrow \\min\\limits_{w,b} $$\n",
    "\n",
    "L1-regularization:\n",
    "\n",
    "$$ Q(X, y, \\theta) = \\sum_{d=1}^D |w_d| + C \\sum_{i=1}^l \\log ( 1 + \\exp(-y_i (w^T x_i + b ) ) ) \\longrightarrow \\min\\limits_{w,b} $$\n",
    "\n",
    "$C$ - это стандартный гиперпараметр модели, который регулирует то, насколько сильно мы позволяем модели подстраиваться под данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Тренировки и тестиро"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Две задачи и одна наука\n",
    "\n",
    "## 1.1 Великий вопрос номер один\n",
    "\n",
    "**Интерпретация.** Пусть мы хотим знать какие именно переменные увеличивают наши шансы закончить эконом и насколько сильно. \n",
    "В нашем распоряжении оказался довольно большой массив данных. От баллов за ЕГЭ до подписок и информации из профилей. Предположим, что мы оценили модель только по баллам ЕГЭ и по наличию олимпиады. Коэффицент перед переменной, отвечающей за наличие олимпиады получился довольно большим. Он равен $42$. \n",
    "\n",
    "Означает ли это, что при наличии олимпиады, мои шансы закончить эконом возрастают пропорционально этому коэффициенту?  Заметьте, я не говорю, что вероятность закончить эконом увеличивается на 42 процентных пункта, потому что мы оцениваем логистическую регрессию. В такой модели интерпретация коэффициентов устроена более сложным образом. Значение коэффициента $\\hat \\beta$ интерпретируется, как величина изменения шансов (смотри 2 том Носко, страницу 205) либо [7 неделю лекций Бориса Борисовича,](https://www.coursera.org/learn/ekonometrika/lecture/JaRpY/7-1-5-loghit-modiel-doska) а лучше и то и то.\n",
    "\n",
    "Так вот, означат ли это, что мои шансы закончить эконом растут пропорционально 42? Нет, не означает. Почему? Потому что вероятность закончить первый курс, в равной степени как и способность написать олимпиаду или хорошо сдать ЕГЭ, зависят от такой ненаблюдаемой переменной, как уровень умственных способностей. Эта переменная, в нашей ситуации оказалась в ошибке. В конечном счёте, из-за её пропуска возникает корреляция регрессора и ошибки, оценки коэффициентов оказываются смещёнными и несостоятельными, а сама по себе эта ситуация, называется **эндогенностью.** В этом месте я хотел бы передать привет третьему курсу, который, по большей части, не мог сформулировать мне на зачёте по эконометрике, определение эндогенности. \n",
    "\n",
    "Так вот, из-за эндогенности, оценки коэффициентов оказываются **смещенными** и **несостоятельными**. Они ни в коей мере не отражают реальность. В связи с этим мы ничерта не можем сказать о влиянии олимпиады на шансы закончить эконом. Для того, чтобы сделать это, нужно добавить в модель какие-то **инструментальные переменные**, которые будут нести в себе информацию об уровне умственных способностей человека. \n",
    "\n",
    "В нашем случае, за создание таких переменных отвечает социальная сеть. Мы наблюдаем за тем, на какие паблики подписывается человек, что он пишет у себя в профиле и так далее. Это позволяет собрать какую-то информацию о его складе ума, характере и других, одному процессу порождения данных ведомых, скрытых от нас характеристиках. В конечном счёте, когда мы добавим в модель эти переменные, мы вынесем ненаблюдаемый эффект из ошибки, корреляция между ошибкой и регрессором исчезнет и оценки в модели получатся состоятельными. \n",
    "\n",
    "Предположим, что оценка коэффициента после всех этих манипуляций, оказалась равна $5$. Если никаких других источников эндогенности не осталось,и, при этом, объём данных был довольно большим, мы, дейтвительно можем сказать, что наличие олимпиды увеличивает шансы человека закончить эконом пропроционально 5. Конечно же, при условии, если коэффициент оказывается значим. \n",
    "\n",
    "Мы боролись за интерпретацию коэффициента перед переменной, отвечающей за олимпиаду и хотели узнать насколько это важно. Можно сказать, что наша борьба закончилась успешно. \n",
    "\n",
    "**Но ведь кроме олимпиады у нас в модели куча других переменных!** Например,  в ней есть переменная, которая отвечает за наличие подписки на мдк. И она равна $-3000$. Означает ли это, что если я прямо сейчас отпишусь от мдк, мои шансы закончить эконом так сильно вырастут? \n",
    "\n",
    "Если вы знали об исследовании и отписались из-за этого, **ничего у вас не вырсатет,** потому что изменилась не причина, а следствие.  Если вы не знали об исследовании, в вашей жизни произошло какое-то переосмысление ценностей, вы поняли, что там тупые мемы, а ботать очень круто, то да. Ваши шансы закончить эконом возрастут. Возрастут не потому что вы отписались от мдк, а потому что что-то произошло с причиной того, что вы на него были подписаны. Произошло что-то с ненаблюдаемой переменной, которая несёт информацию о вашем характере.\n",
    "\n",
    "**Ещё раз, ещё раз,** в первой ситуации, просто-напросто, испортился информационный канал, за который отвечала инструментальная переменная \"паблик мдк\", во втором случае изменилась истиная информация и наш информационный канал в виде инструментальной переменной сообшил нам про это.  Интерпретировать коэффициенты в логистической регрессии можно так и только так. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2  Великий вопрос номер два \n",
    "\n",
    "Прогнозы. Пусть мы хотим уметь хорошо прогнозировать отчислят ли человека с эконома или нет. Предположим, что мы оценили регрессию из предыдущего пункта. Она хороша, коэффициенты хороши, всё значимо, на улице светит солнце, все гиптезы проверены, вода в ручьях кристально чистая, эндогенности нет и во всём мире мир. Можно ли использовать её для прогнозирования? **Конечно да.** Ура, расходимся!\n",
    "\n",
    "**Секундочку. А что если я скажу вам, что ваши прогнозы можно улучшить?** При оценивании логистической регрессии максимизируется логарифм правдоподобия. Этот логарифм можно немного переписать и получить логистическую функцию потерь, которую уже нужно будет минимизировать. Уже к ней можно присобачить дополнительное слагаемое, которое будет отвечать за ограничения, накладываеммые на коэффициенты. Если выбрать перед этим ограничением правильный множатель и проминимизировать всё это добро, то коэффициенты окажутся смещенными, но при этом прогнозы станут лучше. \n",
    "\n",
    "Как такое происходит? А очень просто! [Можно показать,](https://habrahabr.ru/company/ods/blog/323890/) что ошибка прогноза складывается из **квадрата смещения**, **дисперсии** и **неустранимой ошибки**\n",
    "\n",
    "$$\n",
    "Err = Var(\\hat y) + Bias^2(\\hat y) + \\sigma^2 \n",
    "$$\n",
    "\n",
    "\n",
    "Если с последней мы ничего сделать не можем, то на первые два слагаемых мы можем как-то влиять. В идеале, конечно же, хотелось бы свести на нет оба этих слагаемых (левый верхний квадрат рисунка), но на практике часто приходится балансировать между смещенными и нестабильными оценками (высокая дисперсия).\n",
    "\n",
    "<img align=\"center\" src=\"https://hsto.org/files/aa5/d0f/149/aa5d0f149838470fb997ca405c4c55a0.png\" width=\"350\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как правило, при увеличении сложности модели (например, при увеличении количества свободных параметров) увеличивается дисперсия (разброс) оценки, но уменьшается смещение. Из-за того что тренировочный набор данных полностью запоминается вместо обобщения, небольшие изменения приводят к неожиданным результатам (переобучение). Если же модель слабая, то она не состоянии выучить закономерность, в результате выучивается что-то другое, смещенное относительно правильного решения.\n",
    "\n",
    "Наша святая всех святых, **Теорема Гаусса-Маркова** как раз утверждает, что МНК-оценка параметров линейной модели является самой лучшей в классе несмещенных линейных оценок, то есть с наименьшей дисперсией. Вопрос в предпосылках теоремы Гаусса-Маркова. Они практически никогда не выполнены. Это позволяет регуляризатором уменьшить разброс за счёт смещения и улучшить прогнозы. \n",
    "\n",
    "Однако, в этом случае, мы приносим в жертву интерпретацию. Оценки коэффициентов оказываются смещёнными и не отражают никаких реалий. Единственное, на что в такой ситуации можно обращать внимание, это знак коэффициента и его размер. Чем больше абсолютное значение коэффициента, тем более важна эта переменная. Но какой именно вклад она вносит, мы не знаем. \n",
    "\n",
    "Более подробно, со всеми формулами и выводами, об этом (и не только об этом) можно почитать в двух отлично сделанных статьях на хабре. \n",
    "\n",
    "1. [Про переобучение, комплексные собственные значения, регуляризаторы и байесовскую интерпретацию линейных моделей](https://habrahabr.ru/company/ods/blog/322076/)\n",
    "2. [Про линейные модели и логит.](https://habrahabr.ru/company/ods/blog/323890/) На мой взгляд, написано на стыке эконометрики и машинного обучения. \n",
    "\n",
    "Более того, модели можно усложнять. В большей части ситуаций, такое усложнение, делает модель неинтерпретируемой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Классификация\n",
    "\n",
    "Нам предстоит решить задачу классификации: раздробить всех перваков на два вида: закончит первый курс, $1$ и не закончит, $0$. Предположим, что нам в ходе долгих и упорных изысканий удалось обучить несколько моделей. Каждая из моделей выплёвывает нам вероятность того, что человек закончит. Если вероятность оказывается выше какого-то порога, мы ставим единичку. Пришло время сравнить их между собой по качеству. Выбор метрики, с помощью которой это сравнение можно было бы произвести — непременная часть работы дата-шрушера.\n",
    "\n",
    "Перед переходом к самим метрикам необходимо ввести важную концепцию для описания этих метрик в терминах ошибок классификации — confusion matrix (матрица ошибок).\n",
    "Допустим, что у нас есть два класса и алгоритм, предсказывающий принадлежность каждого объекта одному из классов, тогда матрица ошибок классификации будет выглядеть следующим образом:\n",
    "\n",
    "\n",
    "\n",
    "Первая идея, которая приходит в голову — посмотреть на долю правильных ответов алгоритма, accuracy. Эта метрика интуитивно понятна и почти не используется на практике. Она довольно чувствительна к величине порога."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока наш алгоритм выдавал оценки принадлежности к классу 1. Ясно, что на практике нам часто надо будет решить: какие объекты отнести к классу 1, а какие к классу 0. Для этого нужно будет выбрать некоторый порог (объекты с оценками выше порога считаем принадлежащими классу 1, остальные – 0).\n",
    "\n",
    "Выбору порога соответствует выбор точки на ROC-кривой.\n",
    "\n",
    "Заметим, что точка по абсциссе – это процент точек класса 0, которые неверно классифицированы нашим алгоритмом (это называется FPR = False Positive Rate). Заметим, что точка по ординате – процент точек класса 1, которые верно классифицированы нашим алгоритмом (это называется TPR = True Positive Rate). Именно в этих координатах (FPR, TPR) построена ROC-кривая. Часто в литературе её определяют как кривую зависимости TPR от FPR при варьировании порога для бинаризации.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2 Прогнозы,  тренировочная и тестовая выборки, кросс-валидация\n",
    "\n",
    "Сконцентрируемся на прогнозах и постраемся как следует обучить модель, которая могла бы предсказать вероятность отчисления с первого курса. \n",
    "\n",
    "## 2.1 \n",
    "\n",
    "**про тест, трэйн и валидацию и метрики **  \n",
    "\n",
    "\n",
    "У нас есть данные за 2012 - 2016 года. Разделим их в следующей пропорции: на данных за 2012 - 2015 (4 года) будем обучать модель. На данных за 2016 год мы будем тестировать модель. \n",
    "\n",
    "## 2.2 \n",
    "\n",
    "**про самые херовые модели** \n",
    "\n",
    "Обратим внимание на то, что в нашей выборке \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Регрессия - моя профессия \n",
    "\n",
    "Итак, наша основная надежда при таком маленьком объёме данных - линейные модели. Попробуем идти по следующему плану.\n",
    "\n",
    "1. Проскалируем реальные фичи. Категориальные либо выбросим либо превратим в dummy. \n",
    "1. Строим модели отдельно по приказам, стенам, фоткам и пабликам. Смотрим на их прогнозную силу. Отбор переменных делаем с помощью Lasso-регрессии. Смотрим на то как опасны переменные из будущего. \n",
    "2. Строим модель по приказам + профилям, приказам + пабликам и тд, смотрим что из этого выйдет. На этом и всех дальнейших этапах мы будем отбирать фичи по двум стратегиям: Lasso и последовательные тесты на совместную значимость. Все гипотезы будем проверять на уровне значимости 10\\%. Такой уровень значимости связан с размером выборки. \n",
    "3. Строим модель по всему вместе. \n",
    "4. Моя интуиция подсказывает мне, что фотки и стены не дадут никакого профита для наших моделей. Попробуем построить модель без фоток и стен. \n",
    "5. Все модели выше мы будем оценивать на выборке 2012-2015. Оценивать их качество и сравнивать их между собой мы будем на 2016 году. В качестве метры качества модели мы будем использовать ROC-AUC, который нечувствителен к выбору порога. \n",
    "6. Для модели, которая обладает наилучшей прогнозной силой мы выберем самое няшное значение порога, спрогнозируем вероятности и отчисления. \n",
    "7. Ради фана попробуем построить деревья и небольшую нейросетку. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Хочу всё и сразу \n",
    "\n",
    "Обратите внимание, что в этом разделе мы не используем такие переменные как `hodit_para` и `hodit_tusa`. Мы уже обсуждали, что это связано с тем, что они пришли к нам из будущего. В следующем разделе мы ещё раз это обсудим. Попробуем делать по науке. Возьмём наиболее полный объём данных и попробуем оценить модель по всему. После попробуем отобрать переменные двумя способами. \n",
    "\n",
    "1. Последовательно проверяем гипотезы о совместной незначимости коэффициентов, используя тест отношения правдоподобий. Все гипотезы будем проверять на $10\\%$ уровне значимости. При нескольких последовательных тестах на совместную незначимость будем вводить корректировку Бонферрони. \n",
    "2. Добавляем к модели Lasso-регуляризацию, которая сама занулит все коэффициенты, необладающие прогнозной силой. \n",
    "\n",
    "Напомню, что когда мы будем делать селекцию переменных с помощью проверки гипотез, мы будем бороться ещё и за интерпретацию значений коэффициентов в модели. В случае селекции по Lasso, мы будем бороться именно за прогнозы и оценки коэффициентов будут смещены. \n",
    "\n",
    "| Даныне     | Селекция   | Переменных до |Переменных после |Roc-Auc_val |Roc-Auc_test| \n",
    "|------------|------------|---------------|-----------------|------------|------------|\n",
    "| Все+паб_20 |   lasso    | 92            | 11              |  0.60      |  0.65      | \n",
    "| Все+паб_20 |  hypotesis | 92            | 13              |  0.78      |  0.60      |\n",
    "| Все+паб_30 |   lasso    | 102           | 11              |  0.60      |  0.65      |\n",
    "| Все+паб_30 |  hypotesis | 102           |                 |            |            | \n",
    " \n",
    "\n",
    "Оценивание модели с разбиением пабликов на 20 категорий даёт нам следующий значимы результат: \n",
    "\n",
    "```\n",
    "                                              Estimate Std. Error z value Pr(>|z|)    \n",
    "                        (Intercept)             1.3287     0.3441   3.861 0.000113 ***\n",
    "                        ochko.zaochka           1.7032     0.7173   2.374 0.017574 *  \n",
    "                        profile_folowers_cnt   -7.8420     2.5224  -3.109 0.001877 ** \n",
    "                        profile_albums_cnt     15.8210     3.9039   4.053 5.07e-05 ***\n",
    "                        photo_like_mean         0.9388     0.2586   3.630 0.000283 ***\n",
    "                        wall_can_comment        1.6523     0.3895   4.242 2.22e-05 ***\n",
    "                        wall_emoji_mean        -0.3447     0.1827  -1.887 0.059209 .  \n",
    "                        wall_post_android_cnt  -5.7946     1.8019  -3.216 0.001300 ** \n",
    "                        wall_post_ipad_cnt      5.4728     2.5702   2.129 0.033226 *  \n",
    "                        wall_repost_mean       -1.1068     0.4235  -2.613 0.008968 ** \n",
    "                        wall_video_cnt         -2.7091     1.5631  -1.733 0.083060 .  \n",
    "                        wall_video_mean         0.3896     0.2118   1.839 0.065880 .  \n",
    "                        X20pub_clust_9        -59.2349    23.8545  -2.483 0.013022 *  \n",
    "                        X20pub_clust_11        -6.4483     2.5048  -2.574 0.010042 *  \n",
    "```\n",
    "\n",
    "Посмотрим на знаки перед переменными и подумаем насколько они логичны. Имейте в виду, что вся моя дальнейшая интерпретация основа ... ни на чём. Переменная `ochko-zaochka` принимает значений 1, если человек не попал на бюджет, но при этом оставились физтеховские места и ему предложили вариант с обучением на очно-заочном бюджетном режиме с последующим переводом на очный режим. Обычно такой режим обучения предлагают замотивированным студентам, которые хотели бы к нам попасть, но при этом бояться попасть на платку. Положительный знак перед этой переменной не удивляет. \n",
    "\n",
    "Остальные переменные мы пихали в модель в рамках кампании по борьбе с эндогенностью. Все они должны были стать инструментами для некоторых скрытых от наших глаз качеств людей. В связи с этим, они должны интерпретироваться именно в этом ключе. Легче всего проинтерретировать последние две переменные. В девятой теме находятся мусорные группы вроде инстахлама, он мне позвонит и т.п. Большой отрицательный коэффициент перед этой темой вполне логичен. В 11 теме находится музыка. Чем больший удельный вес в интересах человека занимает музыка, тем меньше его шансы закончить эконом. \n",
    "\n",
    "Отрицательный знак перед `profile_folowers_cnt` говорит о том, что большое число подписчиков уменьшеает шансы закончить. Возможно, эта переменная стала индекатором для тп, которые скидывают людей в подписки. Переменные `wall_repost_mean` и `wall_video_cnt` отвечают за среднее число репостов на стене и число видео на стене. Скорее всего, они отлавдивают похожие эффекты. Не очень понятно почему общее число видео действует отрицательно, а среднее положительно. Переменная `wall_can_comment` принимает значение $1$, если человек открыл стену для комментов. Скорее всего, переменная является инструментом для способности человека идти на контак с окружающими. Возможно, что люди с закрытой стеной более замкнуты и это мешает им учиться.  Слабозначимая переменная `wall_emoji_mean` говорит о том, что чем чаще в своих постах человек используем эмодзи, тем меньше его шансы закончить. Наверное, переменная отлавливает инфантильность. \n",
    "\n",
    "Положительный знак перед `profile_albums_cnt`, отвечающей за число албомов, довольно сильно удивлет. Не очень очевидно для какой латентной переменной число албомов могло бы быть инструментом. Точно также удивляет положительный знак перед `photo_like_mean`. Переменные `wall_post_android_cnt` и `wall_post_ipad_cnt` также являются довольно странными. Если верить оценённой модели, люди, которые пользуются андроидом, обладают меньшими шансами окончить факультет. \n",
    "\n",
    "Откровенно говоря, часть переменных оставляет желать лучшего и интерпретируется довольно бредово. Если попробовать оценить модель на 102 переменных, алгоритм без регуляризатора отказывается сходиться. Lasso-регрессия занулила все коэффициенты перед темами. Модели вышли одинаковыми. Это не очень круто. \n",
    "\n",
    "__Главная проблема для нашей модели заключается в том, что в нашей тренировчной выборке лежит всего лишь 278 наблюдений. В среднем на оценку одного коэффицента  тратится 3 наблюдения. Это катастрофически мало. Даже не смотря на то, что мы выкинули из рассмотрения категориальные фичи и всякий мусор, фичей всё ещё очень много. Чтобы решить эту проблему, нам нужно подкопить данных.__ К сожалению, мы не можем ждать ещё несколько лет, поэтому придётся попробовать добиться более высоких прогнозных свойств для нашей модели всеми правдами и неправдами. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Своя модель для каждого датасета и опасности будущего \n",
    "\n",
    "Итак, в нашем распоряжении оказалось слишком много переменных. Попробуем построить модели отдельно по каждой из наших табличек. \n",
    "\n",
    "\n",
    "| Даныне     | Селекция   | Переменных до |Переменных после |Roc-Auc_val |Roc-Auc_test| \n",
    "|------------|------------|---------------|-----------------|------------|------------|\n",
    "| Приказы    | lasso      |      7        |        0        |            |            |\n",
    "| Приказы    | hypothesis |      7        |        1        |    0.59    |   0.68     |\n",
    "| +ходит     | lasso      |      9        |        3        |  ~~0.76~~  | ~~0.85~~   | \n",
    "| +ходит     | hypothesis |      9        |        3        |  ~~0.79~~  | ~~0.86~~   |\n",
    "| профили    | lasso      |      25       |        19       |    0.65    |   0.62     |\n",
    "| профили    | hypothesis |      25       |        1        |    0.60    |   0.64     | \n",
    "| фотки      | lasso      |      8        |        4        |    0.56    |   0.27     | \n",
    "| фотки      | hypothesis |      8        |        1        |    0.55    |   0.58     | \n",
    "| стена      | lasso      |      32       |        9        |    0.67    |   0.53     |\n",
    "| стена      | hypothesis |      32       |        3        |    0.60    |   0.69     |  \n",
    "| паблики 20 | lasso      |      20       |        1        |    0.62    |   0.66     | \n",
    "| паблики 20 | hypothesis |      20       |        2        |    0.60    |   0.51     |\n",
    "| паблики 30 | lasso      |      30       |        5        |    0.62    |   0.61     |  \n",
    "| паблики 30 | hypothesis |      30       |        2        |    0.54    |   0.68     |\n",
    "\n",
    "\n",
    "* При моделирировании только по данным приказов отбор переменных с помощью Lasso-регрессии зануляет все коэффициенты. Отбор переменных с помощью тестирования значимости оставляет в модели только одну переменную `ege_diff`. \n",
    "\n",
    "* Как только мы добавляем в модель переменные `hodit_para` и `hodit_tusa`, при селекции в модели остаются только они. Обе переменные имеют положительный знак и дают модели довольно большую прогнозную силу. Возникает ощущение, что только по этим двум переменным можно строить качественные прогнозы. Однако если мы сделаем это, мы переобучим нашу модель под мнение асессоров, которые оценивали посещаемость пар и тусовок. Напомню, что эти переменные проставлялись уже после отчислений и несут в себе довольно много информации из будущего. Точно такое же высокое качество модели мы получим, если добавим в модель переменные `profile_econom_yes` и `profile_ranepa_yes`. Эти две переменные принимали значение 1, если человек указал в профиле, что учится на экономи или в ранепушке. Напомню, что когда мы качали данные об этом из профилей, мы надеялись поймать информацию о том скрывает ли человек от окружающих своё место обучения. Вместо этого мы поймали информацию из будущего. Сначала человека отчислили, после он удалил из своейго профиля. Точно также высокая важность будет у переменной, которая принимает значение $1$, если я есть у человека в друзьях. У меня в друзьях есть только **достойные люди.** Все эти переменные мы не будем в дальнейшем использовать, а полученые высокие значения ROC-AUC зачеркнём. \n",
    "\n",
    "Забавно, что наличие hodit_para и hodit_tusa оставляет значимой не ege_diff, а kozko.\n",
    "\n",
    "```\n",
    "                        Coefficients:\n",
    "                                    Estimate Std. Error z value Pr(>|z|)    \n",
    "                        (Intercept)   1.5699     0.2509   6.258 3.91e-10 ***\n",
    "                        hodit_para    1.0260     0.1651   6.214 5.18e-10 ***\n",
    "                        hodit_tusa    0.5002     0.1761   2.841   0.0045 ** \n",
    "                        kozko        -0.6787     0.3331  -2.038   0.0416 *  \n",
    "```\n",
    "\n",
    "* Оценивание модели только по профилям даёт неплохой результат. Отбор фичей последовательной проверкой гипотез даёт нам на выход только одну переменную, `profile_albums_cnt`. Отбор фичей по Lasso ведёт себя в 19 раз либеральнее. Прогнозная сила за данными в профилях определённо есть.\n",
    "\n",
    "* Строительство модели только по фоткам не приводит ни к чему хорошему. Прогнозная сила чуть мнее, чем отсуствует. \n",
    "\n",
    "* Построенная по стенкам модель что-видит.  Отбор переменных проверкой гипотез выдаёт нам переменные `wall_can_comment, wall_like_max,  wall_video_mean`. Переменная с максимальным числом лайков имеет отрицательный знак. Кажется модель умеет идентифицировать тп вроде меня. \n",
    "\n",
    "* Строительство модели по 20 тематикам даёт довольно интересный результат. Lasso-модель не зануляет только шестую тему, которую можно проинтерпретировать как образовательную. Проверка гипотез выдаёт нам две переменные. Первая отвечает за музыку и имеет отрицательный знак, вторая за искусство и кино. Перед ней положительный знак.  Строительство модели по 30 тематикам выдаёт что-то похожее. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы: \n",
    "\n",
    "1. Не используем даныне по hodit_para и hodit_tusa \n",
    "2. Судя по всему оценка модели по всем данным сразу не даст хороших результатов, так как стена и фотки не обладают прогнозной силой. Оценивание дополнительных коэффициентов по ним сожрёт кучу информации, чего бы нам не хотелось. Тем не менее, мы должны в этом убедиться. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Ещё модели\n",
    "\n",
    "Всегда будем брать для строительства моделей приказы. В довесок к приказам будем добавлять то, что перечислено в колонке данные. Фотки не будем добавлять никогда. \n",
    "\n",
    "\n",
    "| Даныне          | Селекция   | Переменных до |Переменных после |Roc-Auc_val |Roc-Auc_test| \n",
    "|-----------------|------------|---------------|-----------------|------------|------------|\n",
    "| Проф+Паб20      |   lasso    |     53        |     33          |   0.57     |  0.61      |\n",
    "| Проф+Паб20      |  hypotesis |     53        |     5           |   0.71     |  0.60      |\n",
    "| Проф+Паб30      |   lasso    |     63        |     38          |   0.57     |  0.64      | \n",
    "| Проф+Паб30      |  hypotesis |     63        |     3           |   0.72     |  0.54      | \n",
    "| Проф+стена      |   lasso    |     64        |     10          |   0.60     |  0.66      | мб (ок) \n",
    "| Проф+стена      |  hypotesis |     64        |     7           |   0.74     |  0.51      |\n",
    "| стена + Паб20   |   lasso    |     59        |     3           |   0.60     |  0.65      |\n",
    "| стена + Паб20   | hypotesis  |     59        |     7           |   0.71     |  0.66      | мб (hz)\n",
    "| Проф+стена+паб20|   lasso    |     84        |     10          |   0.60     |  0.66      | \n",
    "| Проф+стена+паб20| hypotesis  |     84        |     12          |   0.76     |  0.55      | \n",
    "| Проф+стена+паб30|   lasso    |     94        |     10          |   0.60     |  0.66      |\n",
    "| Проф+стена+паб30| hypotesis  |     94        |     21          |   0.78     |  0.51      | \n",
    "\n",
    "\n",
    "Настала минутка открвовенности. Мы попробовали несколько разных подходов по строительству моделей. Напомню, что самый плохой ROC-AUC, который бывает - это $0.5$. В случае таких моделей, в данных стоят абсолютные хаос и безнадёжность. Для нас лучшие показатели, которых удалось достичь на тесте, находятся в районе $0.65-0.66$. Этот результат не особо хорош, но как первый рубеж неплох. Когда я только-только начинал работать с этим датасетом, я надеялся, что получится довести показатель до $0.7$. Это конечно не бомба в плане прогнозов, но тоже неплохо. Когда я при первых прогонах увидел roc-auc в районе $0.85$, я офигел. После тщательного анализа, я решил выбросить все переменные, которые на мой взгляд приносят данные из будущего. После при разных модификациях поднять roc-auc назад не удалоcь.\n",
    "\n",
    "Выбираем для прогнозов лучшую модель. Будем выбирать её так, чтобы и на валидации и на тесте были норм р\n",
    "\n",
    "\n",
    "Профили + стена прогнозы: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Находим лучшее по соотношению интерпретация-прогнозы \n",
    "\n",
    "\n",
    "\n",
    "Обязательно написать про переобучение под 2016 год и тп.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Прогнозы и выбор порога\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Нелинейные модели "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ансамбль из моделей "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Итоги "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|имя |вероятность|статус|\n",
    "|---------------|--|--|\n",
    "|Соломник Михаил|0.982999783414|0.0|\n",
    "|Куркин Николай|0.981714945309|1.0|\n",
    "|Скибенко Светлана|0.935710881186|0.0|\n",
    "|Дзюба Артём|0.89332070402|0.0|\n",
    "|Харитонова Марина|0.872252954103|1.0|\n",
    "|Радионова Елена|0.854811972011|1.0|\n",
    "|Ахметзянова Дарья|0.833324045078|0.0|\n",
    "|Говоркова Дарья|0.822455307431|1.0|\n",
    "|Коннова Анастасия|0.791198957618|1.0|\n",
    "|Петайкина Анастасия|0.761507477668|1.0|\n",
    "|Дугарова Александра|0.751035049414|1.0|\n",
    "|Ахмедова Вазифа|0.723959739351|1.0|\n",
    "|Решетов Владислав|0.703234247055|1.0|\n",
    "|Лупарев Евгений|0.69978829122|1.0|\n",
    "|Селищева Анна|0.690993411764|1.0|\n",
    "|Ядав Лолита|0.672608075173|1.0|\n",
    "|Гаджиева Аида|0.647743472397|1.0|\n",
    "|Кусегенов Данислам|0.641170442398|1.0|\n",
    "|Лушина Валерия|0.630855665531|1.0|\n",
    "|Зайцева Анна|0.622628483028|1.0|\n",
    "|Воеводина Алена|0.616787829971|0.0|\n",
    "|Комов Михаил|0.599288856404|1.0|\n",
    "|Рединская Наталья|0.593607568554|1.0|\n",
    "|Самойлова Катя|0.585289741729|1.0|\n",
    "|Жуковская Оксана|0.584031239152|1.0|\n",
    "|Потапова Мария|0.580785570253|1.0|\n",
    "|Шкредов Михаил|0.577813157526|0.0|\n",
    "|Корчагин Максим|0.575004076007|1.0|\n",
    "|Сакович Дарья|0.552666389172|1.0|\n",
    "|Добрынина Екатерина|0.541818308597|1.0|\n",
    "|Кириленко Светлана|0.538297257555|1.0|\n",
    "|Китькова Ирина|0.53625358644|1.0|\n",
    "|Ахметова Зиля|0.518176910413|1.0|\n",
    "|Морозова Виолетта|0.518109350676|1.0|\n",
    "|Семёнова Алёна|0.515156686451|1.0|\n",
    "|Челядинова Екатерина|0.51365086262|1.0|\n",
    "|Ваганова Даша|0.510335716021|0.0|\n",
    "|Аскольская Надежда|0.509279334702|1.0|\n",
    "|Даминова Рита|0.505687175462|1.0|\n",
    "|Ломоносов Даниил|0.505235471376|1.0|\n",
    "|Мидюкин Максим|0.504898501929|1.0|\n",
    "|Руч Камила|0.503612349586|1.0|\n",
    "|Корнилов Валера|0.499082817833|0.0|\n",
    "|Ефремова Ольга|0.493535818475|1.0|\n",
    "|Сидоров Александр|0.490719913554|1.0|\n",
    "|Филимонова Мария|0.478117616795|0.0|\n",
    "|Буханов Денис|0.477340852713|1.0|\n",
    "|Горячева Олеся|0.470293547473|0.0|\n",
    "|Зиновьева Анастасия|0.467445971482|1.0|\n",
    "|Завизион Мария|0.462778634197|0.0|\n",
    "|Аксенова Анна|0.457530695956|1.0|\n",
    "|Гвоздева Елизавета|0.450682509747|1.0|\n",
    "|Хуснутдинова Валерия|0.450622957564|1.0|\n",
    "|Ипатьев Кирилл|0.446754673784|1.0|\n",
    "|Королькевич Глеб|0.44615018492|1.0|\n",
    "|Шакиров Роман|0.442038243107|1.0|\n",
    "|Горила Феличия|0.43029460078|1.0|\n",
    "|Щербаков Александр|0.422021105336|1.0|\n",
    "|Пихеева Валерия|0.402556390114|1.0|\n",
    "|Хачатрян Гарик|0.383667032825|0.0|\n",
    "|Васильченко Алина|0.38291793971|1.0|\n",
    "|Полякова Александра|0.378943516205|0.0|\n",
    "|Муцольгова Зарема|0.36654377932|0.0|\n",
    "|Абасин Хасан|0.362920578569|0.0|\n",
    "|Гулиева Эсет|0.362656339169|0.0|\n",
    "|Миронов Пётр|0.344183663914|0.0|\n",
    "|Казарян Диана|0.322694704785|0.0|\n",
    "|Гулиева Залина|0.315619531449|0.0|\n",
    "|Самотканова Виктория|0.31229398835|1.0|\n",
    "|Зыкин Иван|0.298514489303|0.0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| имя | вероятность| \n",
    "|---------------|--------------|\n",
    "|Дарсигов Микаил|0.949628993285|\n",
    "|Хитрова Анастасия|0.898640630975|\n",
    "|Волкова Анна|0.865172876717|\n",
    "|Кидло Ирина|0.840081141885|\n",
    "|Маинскова Татьяна|0.798136218213|\n",
    "|Потапов Владислав|0.779938124613|\n",
    "|Бурмина Светлана|0.77135376713|\n",
    "|Анискина Валерия|0.719642673625|\n",
    "|Козлов Глеб|0.718002231849|\n",
    "|Гришкина Екатерина|0.717810634903|\n",
    "|Третьяков Дмитрий|0.673201490042|\n",
    "|Владимирова Ольга|0.661656945628|\n",
    "|Даниловская Виктория|0.639147780271|\n",
    "|Хупения  Нино|0.638229340912|\n",
    "|Петрунькова Вероника|0.635636198903|\n",
    "|Шагимарданова Диана|0.630645291613|\n",
    "|Сарафанюк Юрий|0.627011129909|\n",
    "|Никишов Вадим|0.621907176321|\n",
    "|Синицын Сергей|0.584163878783|\n",
    "|Зорькина Анастасия|0.582992358173|\n",
    "|Наумов Николай|0.578257426737|\n",
    "|Габузова Елена|0.5611848179|\n",
    "|Курилкина Юлия|0.548922974172|\n",
    "|Юрова Маргарита|0.547327392545|\n",
    "|Евстафьев Сергей|0.523863490448|\n",
    "|Майорова  Ксения|0.51950280741|\n",
    "|Алиев Самир|0.516404084613|\n",
    "|Еремеев Максим|0.501972455518|\n",
    "|Степанова Анна|0.499572732071|\n",
    "|Никишина Елена|0.495347023188|\n",
    "|Горячёва Полина|0.494093921192|\n",
    "|Мантрова Екатерина|0.491457325713|\n",
    "|Водякова Анна|0.491147167633|\n",
    "|Беляков Юрий|0.490519701155|\n",
    "|Щепилова Ирина|0.485724735501|\n",
    "|Гайнулина Алина|0.481960044648|\n",
    "|Потапова Ульяна|0.481707521667|\n",
    "|Хегедуш Инна|0.481575340769|\n",
    "|Илюшин Станислав|0.471872864949|\n",
    "|Малащенко Наталия|0.464054653256|\n",
    "|Нуртдинов Камиль|0.460958239681|\n",
    "|Васильева Ксения|0.45939089208|\n",
    "|Леохина Александра|0.453847065782|\n",
    "|Башкирова Ксения|0.453807600208|\n",
    "|Ляхова Наталия|0.452878951597|\n",
    "|Семедова Наиля|0.45243572459|\n",
    "|Сороковнина Светлана|0.451156513276|\n",
    "|Зельч Елизавета|0.449621591417|\n",
    "|Шишкин Никита|0.449116542537|\n",
    "|Кичаев Денис|0.442038243107|\n",
    "|Манченко Антонина|0.441659041455|\n",
    "|Евсеева Елизавета|0.436198596341|\n",
    "|Синицина Анастасия|0.433386972073|\n",
    "|Барановская Диана|0.430563604705|\n",
    "|Туркин Артём|0.41630616817|\n",
    "|Макагонова Татьяна|0.41533789402|\n",
    "|Кузьмин Иван|0.404924993501|\n",
    "|Агаметова Эльвида|0.401726775678|\n",
    "|Сорокин Дмитрий|0.397047545904|\n",
    "|Иноземцева Александра|0.379619258879|\n",
    "|Токарева Екатерина|0.378960162454|\n",
    "|Шарков Кирилл|0.376309778769|\n",
    "|Андреева Виктория|0.372986549165|\n",
    "|Пилевец Ольга|0.363187060512|\n",
    "|Сединкина Екатерина|0.338588668673|\n",
    "|Арсеньев Вячеслав|0.300155856398|\n",
    "|Мордасов Владислав|0.299184571825|\n",
    "|Буханцев Никита|0.253546674008|\n",
    "|Богданов Евгений|0.249357871104|\n",
    "|Левин Валерий|0.231460687963|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
