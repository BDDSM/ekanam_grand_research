{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/FUlyankin/ekenam_grand_research/master/images/cover.png\">\n",
    "</center>\n",
    "\n",
    "\n",
    "# <center> Иканам гранд рисёрч </center>\n",
    "## <center>  Часть седьмая: моделирование </center>\n",
    "\n",
    "\n",
    "Проект **Иканам гранд рисёрч** реализуется [Иканам стьюдентс коммьюнити,](https://vk.com/ikanam)\n",
    "в частности [вот этим парнем по имени Филипп.](https://vk.com/ppilif)  Если вы нашли ошибку или у вас есть предложения, замечания, деньги, слава или женщины, можно ему написать. Весь говнокод, использованный в исследовании распостраняется по лицензии [Creative Commons CC BY-NC-SA 4.0.](https://creativecommons.org/licenses/by-nc-sa/4.0/) Его можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала. При наличии технической возможности необходимо также указать активную гиперссылку на [страницу рисёрча.](https://github.com/FUlyankin/ekenam_grand_research) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings     # Игнорирование варнингов\n",
    "warnings.filterwarnings(\"ignore\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np     # Нумпай для векторов \n",
    "import pandas as pd    # Пандас для табличек \n",
    "# Округлять в табличках значения до второго знака\n",
    "pd.set_option('precision', 2)           \n",
    "\n",
    "# Пакеты для графииков\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt                             \n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')   # Правильный стиль графиков   \n",
    "\n",
    "# Пакет для красивых циклов. При желании его можно отключить. Тогда из всех циклов придётся \n",
    "# удалять команду tqdm_notebook.\n",
    "from tqdm import tqdm_notebook   # подробнее: https://github.com/tqdm/tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Две задачи и одна наука \n",
    "\n",
    "Анализ данных — это довольно обширная область знания. Она включает в себя классический матстат, эконометрику, машинное обучение и многие другие более специфические вещи. Анализ данных занимается тем, что ищет ответ на [два великих вопроса:](https://www.coursera.org/learn/ekonometrika/lecture/S7E9y/1-1-1-sut-mietoda-naimien-shikh-kvadratov) \n",
    "\n",
    "* Как устроен мир? Как переменная $y$ зависит от переменной $x$? \n",
    "* Что будет завтра? Как спрогнозировать переменную $y$? \n",
    "\n",
    "Обычно для поиска ответов на эти два вопроса используются модели. Эти модели оцениваются с помощью собранных данных. На работу каждой модели накладываются какие-то ограничения. Оценивая коэффициенты в моделях, мы хотим, чтобы они обладали тремя свойствами: \n",
    "\n",
    "1. **Несмещенность** — если мы оцениваем огромное число моделей, то в среднем мы угадываем истиное значение параметра;\n",
    "2. **Состоятельность** — чем больше данных, тем ближе наши оценки к истине;\n",
    "3. **Эффективность** — разброс нашей оценки минимален в некотором классе оценок, если данные меняются, наша оценка меняется менее сильно, нежели другие.\n",
    "\n",
    "В зависимости от того на какой из двух вопросов мы ищем ответ, мы можем приносить некоторые ограничения в жертву. Переформулируем великие вопросы в контексте нашей проблемы и немного подумаем о жертвах, которые мы собираемя принести анализу данных.\n",
    "\n",
    "## 1.1 Великий вопрос номер один\n",
    "\n",
    "Интерпретация. Пусть мы хотим знать какие именно переменные увеличивают наши шансы закончить эконом и насколько сильно. \n",
    "В нашем распоряжении оказался довольно большой массив данных. От баллов за ЕГЭ до подписок и информации из профилей. Предположим, что мы оценили модель только по баллам ЕГЭ и по наличию олимпиады. Коэффицент перед переменной, отвечающей за наличие олимпиады получился довольно большим. Он равен $42$. \n",
    "\n",
    "Означает ли это, что при наличии олимпиады, мои шансы закончить эконом возрастают пропорционально этому коэффициенту?  Заметьте, я не говорю, что вероятность закончить эконом увеличивается на 42 процентных пункта, потому что мы оцениваем логистическую регрессию. В такой модели интерпретация коэффициентов устроена более сложным образом. Значение коэффициента $\\hat \\beta$ интерпретируется, как величина изменения шансов (смотри 2 том Носко, страницу 205) либо [7 неделю лекций Бориса Борисовича,](https://www.coursera.org/learn/ekonometrika/lecture/JaRpY/7-1-5-loghit-modiel-doska) а лучше и то и то.\n",
    "\n",
    "Так вот, означат ли это, что мои шансы закончить эконом растут пропорционально 42? Нет, не означает. Почему? Потому что вероятность закончить первый курс, в равной степени как и способность написать олимпиаду или хорошо сдать ЕГЭ, зависят от такой ненаблюдаемой переменной, как уровень умственных способностей. Эта переменная, в нашей ситуации оказалась в ошибке. В конечном счёте, из-за её пропуска возникает корреляция регрессора и ошибки, оценки коэффициентов оказываются смещёнными и несостоятельными, а сама по себе эта ситуация, называется **эндогенностью.** В этом месте я хотел бы передать привет третьему курсу, который, по большей части, не мог сформулировать мне на зачёте по эконометрике, определение эндогенности. \n",
    "\n",
    "Так вот, из-за эндогенности, оценки коэффициентов оказываются **смещенными** и **несостоятельными**. Они ни в коей мере не отражают реальность. В связи с этим мы ничерта не можем сказать о влиянии олимпиады на шансы закончить эконом. Для того, чтобы сделать это, нужно добавить в модель какие-то **инструментальные переменные**, которые будут нести в себе информацию об уровне умственных способностей человека. \n",
    "\n",
    "В нашем случае, за создание таких переменных отвечает социальная сеть. Мы наблюдаем за тем, на какие паблики подписывается человек, что он пишет у себя в профиле и так далее. Это позволяет собрать какую-то информацию о его складе ума, характере и других, одному процессу порождения данных ведомых, скрытых от нас характеристиках. В конечном счёте, когда мы добавим в модель эти переменные, мы вынесем ненаблюдаемый эффект из ошибки, корреляция между ошибкой и регрессором исчезнет и оценки в модели получатся состоятельными. \n",
    "\n",
    "Предположим, что оценка коэффициента после всех этих манипуляций, оказалась равна $5$. Если никаких других источников эндогенности не осталось,и, при этом, объём данных был довольно большим, мы, дейтвительно можем сказать, что наличие олимпиды увеличивает шансы человека закончить эконом пропроционально 5. Конечно же, при условии, если коэффициент оказывается значим. \n",
    "\n",
    "Мы боролись за интерпретацию коэффициента перед переменной, отвечающей за олимпиаду и хотели узнать насколько это важно. Можно сказать, что наша борьба закончилась успешно. \n",
    "\n",
    "**Но ведь кроме олимпиады у нас в модели куча других переменных!** Например,  в ней есть переменная, которая отвечает за наличие подписки на мдк. И она равна $-3000$. Означает ли это, что если я прямо сейчас отпишусь от мдк, мои шансы закончить эконом так сильно вырастут? \n",
    "\n",
    "Если вы знали об исследовании и отписались из-за этого, **ничего у вас не вырсатет,** потому что изменилась не причина, а следствие.  Если вы не знали об исследовании, в вашей жизни произошло какое-то переосмысление ценностей, вы поняли, что там тупые мемы, а ботать очень круто, то да. Ваши шансы закончить эконом возрастут. Возрастут не потому что вы отписались от мдк, а потому что что-то произошло с причиной того, что вы на него были подписаны. Произошло что-то с ненаблюдаемой переменной, которая несёт информацию о вашем характере.\n",
    "\n",
    "**Ещё раз, ещё раз,** в первой ситуации, просто-напросто, испортился информационный канал, за который отвечала инструментальная переменная \"паблик мдк\", во втором случае изменилась истиная информация и наш информационный канал в виде инструментальной переменной сообшил нам про это.  Интерпретировать коэффициенты в логистической регрессии можно так и только так. \n",
    "\n",
    "## 1.2  Великий вопрос номер два \n",
    "\n",
    "Прогнозы. Пусть мы хотим уметь хорошо прогнозировать отчислят ли человека с эконома или нет. Предположим, что мы оценили регрессию из предыдущего пункта. Она хороша, коэффициенты хороши, всё значимо, на улице светит солнце, все гиптезы проверены, вода в ручьях кристально чистая, эндогенности нет и во всём мире мир. Можно ли использовать её для прогнозирования? **Конечно да.** Ура, расходимся!\n",
    "\n",
    "Секундочку. А что если я скажу вам, что ваши прогнозы можно улучшить? При оценивании логистической регрессии максимизируется логарифм правдоподобия. Этот логарифм можно немного переписать и получить логистическую функцию потерь. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Самые простые данные \n",
    "\n",
    "Построим логрегрессию по самым простым данным, которые у нас есть. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('data_1_easy.csv',sep='\\t',index_col=0)\n",
    "\n",
    "data1_X = data1[data1.year != 2017].drop(['uids','firstname','lastname','prohodnoy', 'hodit_para','hodit_tusa',\n",
    "        'target_1','target_2','target_3','target_4','kurs','zima','leto','akadem'],axis=1)\n",
    "\n",
    "# Нулями залились только недостающие куски в колонке с целевиками\n",
    "X_tr = data1_X[data1_X.year != 2016].drop('year',axis=1).fillna(0).get_values( )\n",
    "X_val = data1_X[data1_X.year == 2016].drop('year',axis=1).fillna(0).get_values( )\n",
    "\n",
    "y_tr = data1[data1.year < 2016]['target_1'].get_values()\n",
    "y_val = data1[data1.year == 2016]['target_1'].get_values()\n",
    "\n",
    "\n",
    "print('Всего:', data1_X.shape)\n",
    "print('Трэйн:', X_tr.shape, y_tr.shape)\n",
    "print('Тест:', X_val.shape, y_val.shape)\n",
    "\n",
    "print('\\n Метки:', '\\n', y_tr[:10], '\\n')\n",
    "print('Переменные: \\n', X_tr)\n",
    "\n",
    "data1_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score, roc_auc_score, roc_curve, auc\n",
    "\n",
    "n_tr = y_tr.shape[0]\n",
    "n_val = y_val.shape[0]\n",
    "\n",
    "print('Трэйн:')\n",
    "print('accuracy_0 :', accuracy_score(y_tr, [0]*n_tr))\n",
    "print('accuracy_1 :', accuracy_score(y_tr, [1]*n_tr))\n",
    "print('roc-auc:', roc_auc_score(y_tr, np.ones(y_tr.shape)))\n",
    "\n",
    "print( '\\n', 'Тест:')\n",
    "print('accuracy_0 :', accuracy_score(y_val, [0]*n_val))\n",
    "print('accuracy_1 :', accuracy_score(y_val, [1]*n_val))\n",
    "print ('roc-auc:', roc_auc_score(y_val, np.ones(y_val.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printer(y_tr, y_val, model):\n",
    "    y_hat_tr = model.predict_proba(X_tr)[:,1]\n",
    "    y_hat_val = model.predict_proba(X_val)[:,1]\n",
    "    print ('Train logloss', log_loss(y_tr, y_hat_tr ))\n",
    "    print ('Validation logloss', log_loss(y_val,y_hat_val ), '\\n')\n",
    "    print ('Train accuracy', accuracy_score(y_tr, model.predict(X_tr)))\n",
    "    print ('Validation accuracy', accuracy_score(y_val, model.predict(X_val)), '\\n')\n",
    "    print ('Train roc-auc', roc_auc_score(y_tr, y_hat_tr))\n",
    "    print ('Validation roc-auc', roc_auc_score(y_val, y_hat_val))\n",
    "    \n",
    "def roc_auc_pic(y_tr,y_val,model):\n",
    "    y_hat_tr = model.predict_proba(X_tr)[:,1]\n",
    "    y_hat_val = model.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    fpr_train, tpr_train, thresholds_train = roc_curve(y_tr, y_hat_tr)\n",
    "    fpr_test, tpr_test, thresholds_test = roc_curve(y_val, y_hat_val)\n",
    "    roc_auc_train = roc_auc_score(y_tr, y_hat_tr)\n",
    "    roc_auc_test = roc_auc_score(y_val, y_hat_val)\n",
    "\n",
    "\n",
    "    matplotlib.rcParams['figure.figsize'] = (5, 5)\n",
    "    plt.plot(fpr_train, tpr_train, label='Train ROC AUC {0}'.format(roc_auc_train))\n",
    "    plt.plot(fpr_test, tpr_test, label='Test ROC AUC {0}'.format(roc_auc_test))\n",
    "    plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6))\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Logit', size=16)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "printer(y_tr, y_val, lr)\n",
    "roc_auc_pic(y_tr,y_val, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Качество модели на кросс-валидации \n",
    "from sklearn.cross_validation import cross_val_score\n",
    "scoring = cross_val_score(lr, X_tr, y_tr, scoring = 'accuracy', cv =5)\n",
    "print(scoring.mean())\n",
    "scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in zip(data1_X.columns.get_values(), lr.coef_[0]):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "parameters_grid = {\n",
    "    # 'penalty' : ['l1', 'l2'],\n",
    "    'C' : np.linspace(0.0000000001, 2, num = 200)\n",
    "}\n",
    "\n",
    "gridsearch = GridSearchCV(LogisticRegression(penalty = 'l1'), parameters_grid, scoring = 'log_loss', cv = 3)\n",
    "gridsearch.fit(X_tr, y_tr)\n",
    "\n",
    "def plot_scores(optimizer):\n",
    "    print( optimizer.best_params_)\n",
    "    scores = [[item[0]['C'], \n",
    "               item[1], \n",
    "               (np.sum((item[2]-item[1])**2)/(item[2].size-1))**0.5] for item in optimizer.grid_scores_]\n",
    "    scores = np.array(scores)\n",
    "    plt.semilogx(scores[:,0], scores[:,1])\n",
    "    plt.fill_between(scores[:,0], scores[:,1]-scores[:,2], \n",
    "                                  scores[:,1]+scores[:,2], alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "plot_scores(gridsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printer(y_tr, y_val, gridsearch.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in zip(data1_X.columns.get_values(), gridsearch.best_estimator_.coef_[0]):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Данные по профилю вк "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('prof_data.csv',sep='\\t')\n",
    "\n",
    "data2_X = data2[data2.year != 2017].drop(['uids','uid','firstname','lastname','year','prohodnoy', \n",
    "                                        'hodit_para','hodit_tusa',\n",
    "        'target_1','target_2','target_3','target_4','kurs','zima','leto','akadem'],axis=1)\n",
    "\n",
    "#data2_X.drop(['EGE','lgota','chelevoe','olimp','dogovor','ochko-zaochka','ege_diff','kozko'],axis=1,inplace=True)\n",
    "\n",
    "data2_X.drop(['profile_first_name', 'profile_last_name'],axis=1,inplace=True)\n",
    "\n",
    "data2_X.drop([item for item in list(data2_X.columns) if item[-3:] == 'cat'],axis=1,inplace=True)\n",
    "\n",
    "print(data2_X.shape)\n",
    "data2_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нулями залились только недостающие куски в колонке с целевиками\n",
    "X = data2_X.fillna(0).get_values( )\n",
    "\n",
    "y = data2[data2.year != 2017]['target_1'].get_values()\n",
    "print('Метки:', '\\n', y[:10], '\\n')\n",
    "print('Переменные: \\n', X)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "print('\\n', 'Размеры трэйна и теста:', X_tr.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_tr, y_tr)\n",
    "\n",
    "printer(y_tr, y_val, lr)\n",
    "roc_auc_pic(y_tr,y_val, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in zip(data2_X.columns.get_values(), lr.coef_[0]):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch = GridSearchCV(LogisticRegression(penalty = 'l1'), parameters_grid, scoring = 'log_loss', cv = 3)\n",
    "gridsearch.fit(X_tr, y_tr)\n",
    "plot_scores(gridsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printer(y_tr, y_val, gridsearch.best_estimator_)\n",
    "roc_auc_pic(y_tr,y_val, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in zip(data2_X.columns.get_values(), gridsearch.best_estimator_.coef_[0]):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Качество модели на кросс-валидации \n",
    "from sklearn.cross_validation import cross_val_score\n",
    "scoring = cross_val_score(lr, X_tr, y_tr, scoring = 'accuracy', cv =5)\n",
    "print(scoring.mean())\n",
    "scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=10,max_features='sqrt')\n",
    "rf.fit(X_tr, y_tr)\n",
    "\n",
    "printer(y_tr, y_val, rf)\n",
    "roc_auc_pic(y_tr,y_val, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = cross_val_score(rf, X_tr, y_tr, scoring = 'accuracy', cv =5)\n",
    "print(scoring.mean())\n",
    "scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Только фотки \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ph = pd.read_csv('../1.Download_vk_data/vk_photo_data_v18-12-17.csv', sep = '\\t', index_col=0)\n",
    "df_ph.drop(['photo_text'], axis=1, inplace= True )\n",
    "\n",
    "data3 = pd.read_csv('data_1_easy.csv',sep='\\t',index_col=0)\n",
    "\n",
    "data3_X = data1[data3.year != 2017].drop(['firstname','lastname','year','prohodnoy', 'hodit_para','hodit_tusa',\n",
    "        'target_1','target_2','target_3','target_4','kurs','zima','leto','akadem'],axis=1)\n",
    "\n",
    "data3_X = pd.merge(df_ph, data3_X, right_on='uids', left_on='uid',how='right')\n",
    "data3_X.drop(['uid','uids'],axis=1,inplace=True)\n",
    "\n",
    "data3_X.drop(['EGE','lgota','chelevoe','olimp','dogovor','ochko-zaochka','ege_diff','kozko'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "print(data3_X.shape)\n",
    "\n",
    "data1_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нулями залились только недостающие куски в колонке с целевиками\n",
    "X = data3_X.fillna(0).get_values( )\n",
    "\n",
    "y = data1[data1.year != 2017]['target_1'].get_values()\n",
    "print('Метки:', '\\n', y[:10], '\\n')\n",
    "print('Переменные: \\n', X)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "print('\\n', 'Размеры трэйна и теста:', X_tr.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_tr, y_tr)\n",
    "\n",
    "printer(y_tr, y_val, lr)\n",
    "roc_auc_pic(y_tr,y_val, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch = GridSearchCV(LogisticRegression(penalty = 'l1'), parameters_grid, scoring = 'log_loss', cv = 3)\n",
    "gridsearch.fit(X_tr, y_tr)\n",
    "plot_scores(gridsearch)\n",
    "\n",
    "printer(y_tr, y_val, gridsearch.best_estimator_)\n",
    "roc_auc_pic(y_tr,y_val, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in zip(data3_X.columns.get_values(), lr.coef_[0]):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"http://img0.reactor.cc/pics/post/ванга-мемгенератор-59018.jpeg\" width=\"300\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
